{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The overall selection of data and the analysis protocol has been loosely borrowed from Kim et al. (2016). Typically for a machine learning problem, we shall have a dataset (consolidated, with class and variable/ feature definitions) and that'll be bifurcated (typically in 3:7 or 2:8 proportions) to be used as testing and training sets respectively. Contrarily, in this study both the categories have been sourced differently as you'll see.\n",
    "In this exercise, we shall have positive and negative training examples for the training dataset but only positive examples for the test dataset. And that is perfectively fine.</p>\n",
    "<p>The H1 cell line data for H3K27, H3K4me1, HeK4me2, and H3K4me3 have been sourced from the [ENCODE project](https://www.encodeproject.org/) featured by [Ren Lab](http://renlab.sdsc.edu/renlab_website/bing/). The version of the genome considered is **GrCh38**.</p>\n",
    "<p>The *bam* data is downloaded and needs to be converted to bed/bw files for further processing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The individual bam files are indexed.\n",
    "\n",
    "system(\"samtools index -b ./H1_GrCh38/H3K27ac/ENCFF663SAM.bam\")\n",
    "system(\"samtools index -b ./H1_GrCh38/H3K4me1/ENCFF441KOL.bam\")\n",
    "system(\"samtools index -b ./H1_GrCh38/H3K4me2/ENCFF799BDH.bam\")\n",
    "system(\"samtools index -b ./H1_GrCh38/H3K4me3/ENCFF340UJK.bam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the BAM files indexed, we proceed towards binning them into the desired intervals of 2000bp (since that is the aggregate size of the enhancers) ans for consistency the non-enhancer segaments shall be of the same size as well. We achieve this via **deeptools** suite, a function called [bamCoverage](https://deeptools.readthedocs.io/en/develop/content/tools/bamCoverage.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"bamCoverage --bam ENCFF663SAM.bam -o ENCFF663SAM2000_30.bw --binSize 2000 --normalizeUsing RPKM --effectiveGenomeSize 2913022398 --outFileFormat bedgraph --maxFragmentLength 30\")\n",
    "system(\"bamCoverage --bam ENCFF441KOL.bam -o ENCFF441KOL2000_36.bw --binSize 2000 --normalizeUsing RPKM --effectiveGenomeSize 2913022398 --outFileFormat bedgraph --maxFragmentLength 36\")\n",
    "system(\"bamCoverage --bam ENCFF799BDH.bam -o ENCFF799BDH2000_36.bw --binSize 2000 --normalizeUsing RPKM --effectiveGenomeSize 2913022398 --outFileFormat bedgraph --maxFragmentLength 36\")\n",
    "system(\"bamCoverage --bam ENCFF340UJK.bam -o ENCFF340UJK2000_36.bw --binSize 2000 --normalizeUsing RPKM --effectiveGenomeSize 2913022398 --outFileFormat bedgraph --maxFragmentLength 36\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above resultant files are the genome-wide coverages of the respective histone marks in the given cell (H1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./props/Data_Schema.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purposes, we consider data only for enhancers. Even with this data alone, we shall be able to evaluate the model's veracity of predicting positive examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted, the primary step is to source the BAM files, index them, and finally tranform into BEDGRAPH files. The column naming is done appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3k27ac <- read.csv(\"./data/H1_Cell_Line/H3K27ac/ENCFF663SAM2000_30.bw\", sep = '\\t', header = FALSE)\n",
    "colnames(h3k27ac) <- c(\"chrom\",\"start\",\"end\",\"reads\")   \n",
    "h3k4me3 <- read.csv(\"./data/H1_Cell_Line/H3K4me3/ENCFF340UJK2000_36.bw\", sep = '\\t', header = FALSE)\n",
    "colnames(h3k4me3) <- c(\"chrom\",\"start\",\"end\",\"reads\")\n",
    "h3k4me2 <- read.csv(\"./data/H1_Cell_Line/H3K4me2/ENCFF799BDH2000_36.bw\", sep = '\\t', header = FALSE)\n",
    "colnames(h3k4me2) <- c(\"chrom\",\"start\",\"end\",\"reads\")\n",
    "h3k4me1 <- read.csv(\"./data/H1_Cell_Line/H3K4me1/ENCFF441KOL2000_36.bw\", sep = '\\t', header = FALSE)\n",
    "colnames(h3k4me1) <- c(\"chrom\",\"start\",\"end\",\"reads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual RPKM levels of the histone marks are stacked together over the 2000bp intervals that represent the probable enhancers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedtools_unionbedg_all.bw <- system (\"bedtools unionbedg -i ./data/H1_Cell_Line/H3K27ac/ENCFF663SAM2000_30.bw ./data/H1_Cell_Line/H3K4me3/ENCFF340UJK2000_36.bw ./data/H1_Cell_Line/H3K4me2/ENCFF799BDH2000_36.bw ./data/H1_Cell_Line/H3K4me1/ENCFF441KOL2000_36.bw -header -names H3K27ac H3K4me3 H3K4me2 H3K4me1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>chrom</th><th scope=col>start</th><th scope=col>end</th><th scope=col>H3K27ac</th><th scope=col>H3K4me3</th><th scope=col>H3K4me2</th><th scope=col>H3K4me1</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>chr1</td><td>    0</td><td> 8000</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td></tr>\n",
       "\t<tr><td>chr1</td><td> 8000</td><td>12000</td><td>0</td><td>0</td><td>0</td><td>0.0568576</td></tr>\n",
       "\t<tr><td>chr1</td><td>12000</td><td>16000</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td></tr>\n",
       "\t<tr><td>chr1</td><td>16000</td><td>18000</td><td>0</td><td>0</td><td>0</td><td>0.0568576</td></tr>\n",
       "\t<tr><td>chr1</td><td>18000</td><td>40000</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td></tr>\n",
       "\t<tr><td>chr1</td><td>40000</td><td>42000</td><td>0</td><td>0</td><td>0</td><td>0.0568576</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       " chrom & start & end & H3K27ac & H3K4me3 & H3K4me2 & H3K4me1\\\\\n",
       " <fct> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t chr1 &     0 &  8000 & 0 & 0 & 0 & 0.0000000\\\\\n",
       "\t chr1 &  8000 & 12000 & 0 & 0 & 0 & 0.0568576\\\\\n",
       "\t chr1 & 12000 & 16000 & 0 & 0 & 0 & 0.0000000\\\\\n",
       "\t chr1 & 16000 & 18000 & 0 & 0 & 0 & 0.0568576\\\\\n",
       "\t chr1 & 18000 & 40000 & 0 & 0 & 0 & 0.0000000\\\\\n",
       "\t chr1 & 40000 & 42000 & 0 & 0 & 0 & 0.0568576\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| chrom &lt;fct&gt; | start &lt;int&gt; | end &lt;int&gt; | H3K27ac &lt;dbl&gt; | H3K4me3 &lt;dbl&gt; | H3K4me2 &lt;dbl&gt; | H3K4me1 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| chr1 |     0 |  8000 | 0 | 0 | 0 | 0.0000000 |\n",
       "| chr1 |  8000 | 12000 | 0 | 0 | 0 | 0.0568576 |\n",
       "| chr1 | 12000 | 16000 | 0 | 0 | 0 | 0.0000000 |\n",
       "| chr1 | 16000 | 18000 | 0 | 0 | 0 | 0.0568576 |\n",
       "| chr1 | 18000 | 40000 | 0 | 0 | 0 | 0.0000000 |\n",
       "| chr1 | 40000 | 42000 | 0 | 0 | 0 | 0.0568576 |\n",
       "\n"
      ],
      "text/plain": [
       "  chrom start end   H3K27ac H3K4me3 H3K4me2 H3K4me1  \n",
       "1 chr1      0  8000 0       0       0       0.0000000\n",
       "2 chr1   8000 12000 0       0       0       0.0568576\n",
       "3 chr1  12000 16000 0       0       0       0.0000000\n",
       "4 chr1  16000 18000 0       0       0       0.0568576\n",
       "5 chr1  18000 40000 0       0       0       0.0000000\n",
       "6 chr1  40000 42000 0       0       0       0.0568576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>chrom</th><th scope=col>start</th><th scope=col>end</th><th scope=col>H3K27ac</th><th scope=col>H3K4me3</th><th scope=col>H3K4me2</th><th scope=col>H3K4me1</th><th scope=col>Class</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>chr1</td><td>    0</td><td> 8000</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td> 8000</td><td>12000</td><td>0</td><td>0</td><td>0</td><td>0.0568576</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>12000</td><td>16000</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>16000</td><td>18000</td><td>0</td><td>0</td><td>0</td><td>0.0568576</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>18000</td><td>40000</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>40000</td><td>42000</td><td>0</td><td>0</td><td>0</td><td>0.0568576</td><td>enhancer</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 8\n",
       "\\begin{tabular}{r|llllllll}\n",
       " chrom & start & end & H3K27ac & H3K4me3 & H3K4me2 & H3K4me1 & Class\\\\\n",
       " <fct> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t chr1 &     0 &  8000 & 0 & 0 & 0 & 0.0000000 & enhancer\\\\\n",
       "\t chr1 &  8000 & 12000 & 0 & 0 & 0 & 0.0568576 & enhancer\\\\\n",
       "\t chr1 & 12000 & 16000 & 0 & 0 & 0 & 0.0000000 & enhancer\\\\\n",
       "\t chr1 & 16000 & 18000 & 0 & 0 & 0 & 0.0568576 & enhancer\\\\\n",
       "\t chr1 & 18000 & 40000 & 0 & 0 & 0 & 0.0000000 & enhancer\\\\\n",
       "\t chr1 & 40000 & 42000 & 0 & 0 & 0 & 0.0568576 & enhancer\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 8\n",
       "\n",
       "| chrom &lt;fct&gt; | start &lt;int&gt; | end &lt;int&gt; | H3K27ac &lt;dbl&gt; | H3K4me3 &lt;dbl&gt; | H3K4me2 &lt;dbl&gt; | H3K4me1 &lt;dbl&gt; | Class &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| chr1 |     0 |  8000 | 0 | 0 | 0 | 0.0000000 | enhancer |\n",
       "| chr1 |  8000 | 12000 | 0 | 0 | 0 | 0.0568576 | enhancer |\n",
       "| chr1 | 12000 | 16000 | 0 | 0 | 0 | 0.0000000 | enhancer |\n",
       "| chr1 | 16000 | 18000 | 0 | 0 | 0 | 0.0568576 | enhancer |\n",
       "| chr1 | 18000 | 40000 | 0 | 0 | 0 | 0.0000000 | enhancer |\n",
       "| chr1 | 40000 | 42000 | 0 | 0 | 0 | 0.0568576 | enhancer |\n",
       "\n"
      ],
      "text/plain": [
       "  chrom start end   H3K27ac H3K4me3 H3K4me2 H3K4me1   Class   \n",
       "1 chr1      0  8000 0       0       0       0.0000000 enhancer\n",
       "2 chr1   8000 12000 0       0       0       0.0568576 enhancer\n",
       "3 chr1  12000 16000 0       0       0       0.0000000 enhancer\n",
       "4 chr1  16000 18000 0       0       0       0.0568576 enhancer\n",
       "5 chr1  18000 40000 0       0       0       0.0000000 enhancer\n",
       "6 chr1  40000 42000 0       0       0       0.0568576 enhancer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Importing the merged BEDGRAPH/BW file\n",
    "\n",
    "merged_bw <- read.csv(\"bedtools_unionbedg_all.bw\", sep = '\\t', header = TRUE)\n",
    "head(merged_bw)\n",
    "merged_bw$Class <- \"enhancer\"\n",
    "head(merged_bw)\n",
    "\n",
    "\n",
    "## Identifying examples of standard chromosomes only and filtering the residuals.\n",
    "\n",
    "chromosomes <- c(\"chr1\",\"chr2\",\"chr3\",\"chr4\",\"chr5\",\"chr6\",\"chr7\",\"chr8\",\"chr9\",\"chr10\",\"chr11\",\"chr12\",\"chr13\",\"chr14\",\n",
    "                 \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\",\"chr21\", \"chr22\", \"chrX\", \"chrY\")\n",
    "merged_bw<- as.data.frame(merged_bw[merged_bw$chrom %in% chromosomes, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As highlighted in the **bamCoverage** operation, the values are the RPKM levels. *RPKM(reads per kilobase per million) : RPKM (per bin) = number of reads per bin / ( number of mapped reads (in millions) * bin length (kb) )*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are soleley concerned with the score values, we shall hack off the information on intervals and chromosome names. The resultant dataset shall have class labels (enhancers) and coverage scores spanning from columns 4 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deriving test data as input to the deep learning model.\n",
    "\n",
    "test <- merged_bw[,c(4:8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>H3K27ac</th><th scope=col>H3K4me3</th><th scope=col>H3K4me2</th><th scope=col>H3K4me1</th><th scope=col>Class</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.0568576</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.0568576</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.0568576</td><td>enhancer</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " H3K27ac & H3K4me3 & H3K4me2 & H3K4me1 & Class\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0 & 0 & 0 & 0.0000000 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.0568576 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.0000000 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.0568576 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.0000000 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.0568576 & enhancer\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| H3K27ac &lt;dbl&gt; | H3K4me3 &lt;dbl&gt; | H3K4me2 &lt;dbl&gt; | H3K4me1 &lt;dbl&gt; | Class &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 0 | 0 | 0 | 0.0000000 | enhancer |\n",
       "| 0 | 0 | 0 | 0.0568576 | enhancer |\n",
       "| 0 | 0 | 0 | 0.0000000 | enhancer |\n",
       "| 0 | 0 | 0 | 0.0568576 | enhancer |\n",
       "| 0 | 0 | 0 | 0.0000000 | enhancer |\n",
       "| 0 | 0 | 0 | 0.0568576 | enhancer |\n",
       "\n"
      ],
      "text/plain": [
       "  H3K27ac H3K4me3 H3K4me2 H3K4me1   Class   \n",
       "1 0       0       0       0.0000000 enhancer\n",
       "2 0       0       0       0.0568576 enhancer\n",
       "3 0       0       0       0.0000000 enhancer\n",
       "4 0       0       0       0.0568576 enhancer\n",
       "5 0       0       0       0.0000000 enhancer\n",
       "6 0       0       0       0.0568576 enhancer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep learning model has two basic requisites with the input data.\n",
    "1. The data has to be *numeric* in type.\n",
    "2. It has to range from 0 to 1. So if it isn't already, some sort of normalization procedure can help do that. The preferred one is the min-max normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have already scanned the dataset for existence of NA values and there exist none. \n",
    "\n",
    "## Min-Max normalization\n",
    "test$H3K27ac <- (test$H3K27ac-min(test$H3K27ac, na.rm = T))/(max(test$H3K27ac, na.rm = T)-min(test$H3K27ac, na.rm = T))\n",
    "test$H3K4me3 <- (test$H3K4me3-min(test$H3K4me3, na.rm = T))/(max(test$H3K4me3, na.rm = T)-min(test$H3K4me3, na.rm = T))\n",
    "test$H3K4me2 <- (test$H3K4me2-min(test$H3K4me2, na.rm = T))/(max(test$H3K4me2, na.rm = T)-min(test$H3K4me2, na.rm = T))\n",
    "test$H3K4me1 <- (test$H3K4me1-min(test$H3K4me1, na.rm = T))/(max(test$H3K4me1, na.rm = T)-min(test$H3K4me1, na.rm = T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>H3K27ac</th><th scope=col>H3K4me3</th><th scope=col>H3K4me2</th><th scope=col>H3K4me1</th><th scope=col>Class</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.000000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.003164557</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.000000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.003164557</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.000000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0.003164557</td><td>enhancer</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " H3K27ac & H3K4me3 & H3K4me2 & H3K4me1 & Class\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0 & 0 & 0 & 0.000000000 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.003164557 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.000000000 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.003164557 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.000000000 & enhancer\\\\\n",
       "\t 0 & 0 & 0 & 0.003164557 & enhancer\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| H3K27ac &lt;dbl&gt; | H3K4me3 &lt;dbl&gt; | H3K4me2 &lt;dbl&gt; | H3K4me1 &lt;dbl&gt; | Class &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 0 | 0 | 0 | 0.000000000 | enhancer |\n",
       "| 0 | 0 | 0 | 0.003164557 | enhancer |\n",
       "| 0 | 0 | 0 | 0.000000000 | enhancer |\n",
       "| 0 | 0 | 0 | 0.003164557 | enhancer |\n",
       "| 0 | 0 | 0 | 0.000000000 | enhancer |\n",
       "| 0 | 0 | 0 | 0.003164557 | enhancer |\n",
       "\n"
      ],
      "text/plain": [
       "  H3K27ac H3K4me3 H3K4me2 H3K4me1     Class   \n",
       "1 0       0       0       0.000000000 enhancer\n",
       "2 0       0       0       0.003164557 enhancer\n",
       "3 0       0       0       0.000000000 enhancer\n",
       "4 0       0       0       0.003164557 enhancer\n",
       "5 0       0       0       0.000000000 enhancer\n",
       "6 0       0       0       0.003164557 enhancer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant data that has been preprocessed explicitly. This is for the positive class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the positive class labels have to be featured around 2000bp intervals as well, we need to synchronise the data in accordance. The individual BED files for the DHS and p300 binding sites that comprehend enhancers are downloaded for the relevant cell type and sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in download.file(\"ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM878nnn/GSM878621/suppl/GSM878621%5FUW%2EH1%2EChromatinAccessibility%2EDS19100%2Ebed%2Egz\", : cannot open URL 'ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM878nnn/GSM878621/suppl/GSM878621%5FUW%2EH1%2EChromatinAccessibility%2EDS19100%2Ebed%2Egz'\n",
     "output_type": "error",
     "traceback": [
      "Error in download.file(\"ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM878nnn/GSM878621/suppl/GSM878621%5FUW%2EH1%2EChromatinAccessibility%2EDS19100%2Ebed%2Egz\", : cannot open URL 'ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM878nnn/GSM878621/suppl/GSM878621%5FUW%2EH1%2EChromatinAccessibility%2EDS19100%2Ebed%2Egz'\nTraceback:\n",
      "1. download.file(\"ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM878nnn/GSM878621/suppl/GSM878621%5FUW%2EH1%2EChromatinAccessibility%2EDS19100%2Ebed%2Egz\", \n .     \"./GSM878621_H1_DNase.bed.gz\")"
     ]
    }
   ],
   "source": [
    "download.file(\"ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM878nnn/GSM878621/suppl/GSM878621%5FUW%2EH1%2EChromatinAccessibility%2EDS19100%2Ebed%2Egz\", \"./data/H1_Cell_Line/GSM878621_H1_DNase.bed.gz\")\n",
    "download.file(\"ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM831nnn/GSM831036/suppl/GSM831036%5F635EFAAXX%2E4%2EH1%5FP300%2Ealn%2Ebed%2Egz\",\"./data/H1_Cell_Line/GSM831036_H1_P300.bed.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"gunzip ./data/H1_Cell_Line/GSM878621_H1_DNase.bed.gz\")\n",
    "system(\"gunzip ./data/H1_Cell_Line/GSM831036_H1_P300.bed.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sortBed is a function available from bedtools. Ensure that it is installed prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"sortBed -i ./data/H1_Cell_Line/GSM878621_H1_DNase.bed > ./data/H1_Cell_Line/GSM878621_H1_DNase_sorted.bed\")\n",
    "system(\"sortBed -i ./data/H1_Cell_Line/GSM831036_H1_P300.bed > ./data/H1_Cell_Line/GSM831036_H1_P300_sorted.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have BED files for p300 and DHS that are: <br>\n",
    ">1. pruned for standard chromosome entries <br>\n",
    ">2. sorted <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with DNase Hypersensitivity Sites (DHS) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few functional packages shall be necessary here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bioconductor version 3.4 (BiocManager 1.30.10), R 3.3.3 (2017-03-06)\n",
      "\n",
      "Installing package(s) 'BiocVersion', 'rtracklayer', 'GenomicRanges',\n",
      "  'GenomeInfoDb'\n",
      "\n",
      "Warning message:\n",
      "“package ‘BiocVersion’ is not available (for R version 3.3.3)”\n",
      "also installing the dependencies ‘XML’, ‘RCurl’\n",
      "\n",
      "\n",
      "Warning message:\n",
      "“unable to access index for repository https://bioconductor.org/packages/3.4/workflows/bin/macosx/mavericks/contrib/3.3:\n",
      "  cannot download all files”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  There are binary versions available but the source versions are later:\n",
      "         binary    source needs_compilation\n",
      "XML    3.98-1.9 3.98-1.20              TRUE\n",
      "RCurl 1.95-4.10 1.95-4.12              TRUE\n",
      "\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/x9/w89rq3h57qvd9tnz_t48ld6w0000gn/T//RtmpwEB5M8/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "installing the source packages ‘XML’, ‘RCurl’\n",
      "\n",
      "\n",
      "Warning message in install.packages(...):\n",
      "“installation of package ‘XML’ had non-zero exit status”\n",
      "Warning message in install.packages(...):\n",
      "“installation of package ‘RCurl’ had non-zero exit status”\n",
      "Old packages: 'KernSmooth', 'MASS', 'Matrix', 'boot', 'class', 'cluster',\n",
      "  'codetools', 'foreign', 'lattice', 'mgcv', 'repr', 'rpart'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
    "    install.packages(\"BiocManager\")\n",
    "BiocManager::install(c(\"rtracklayer\", \"GenomicRanges\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding file is sifted for standard chromosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: GenomicRanges\n",
      "\n",
      "Loading required package: GenomeInfoDb\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package ‘GenomeInfoDb’ could not be loaded\n",
     "output_type": "error",
     "traceback": [
      "Error: package ‘GenomeInfoDb’ could not be loaded\nTraceback:\n",
      "1. library(rtracklayer)",
      "2. .getRequiredPackages2(pkgInfo, quietly = quietly)",
      "3. library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = lib.loc, \n .     quietly = quietly)",
      "4. .getRequiredPackages2(pkgInfo, quietly = quietly)",
      "5. stop(gettextf(\"package %s could not be loaded\", sQuote(pkg)), \n .     call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "## Calling libraries\n",
    "\n",
    "library(rtracklayer)\n",
    "library(GenomicRanges)\n",
    "\n",
    "dhs_rev <- import.bed(\"./data/H1_Cell_Line/GSM878621_H1_DNase_sorted.bed\")\n",
    "chromosomes <- c(\"chr1\",\"chr2\",\"chr3\",\"chr4\",\"chr5\",\"chr6\",\"chr7\",\"chr8\",\"chr9\",\"chr10\",\"chr11\",\"chr12\",\"chr13\",\"chr14\",\n",
    "                 \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\",\"chr21\", \"chr22\", \"chrX\", \"chrY\")\n",
    "dhs_rev_chr <- dhs_rev[seqnames(dhs_rev) %in% chromosomes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our quest for enhancer prediction would likely require us to examine 2000bp regions. The bins are resized in accordance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_rev_chr_resize <- resize(dhs_rev_chr, width = 2000)\n",
    "dhs_final <- as.data.frame(dhs_rev_chr_resize)\n",
    "export.bed(dhs_final[,1:3], \"dhs_final.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are considering the basic attributes of genomic regions, i.e. chromosomal locations marked by chromosome, start index, and end index. To ensure sanctity of the data, let's check if things are placed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data integrity\n",
    "\n",
    "system(\"awk '$2>0 && $3>$2 {print $1 \"\\t\" $2 \"\\t\" $3}' dhs_final.bed > dhs_finale.bed\")\n",
    "system(\"sortBed -i dhs_finale.bed > dhs_finale_sorted.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good for now. Next, we treat the p300 binding sites' data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with p300 bindings on the genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We shall aggregately adhere to the same protocol for data treatment.\n",
    "\n",
    "p300_rev <- import.bed(\"./data/H1_Cell_Line/GSM831036_H1_P300_sorted.bed\")\n",
    "BiocManager::install(\"diffloop\")\n",
    "library(diffloop)\n",
    "p300_rev <- addchr(p300_rev) # Add prefix \"chr\" to the seqnames #\n",
    "p300_rev_chr <- p300_rev[seqnames(p300_rev) %in% chromosomes]\n",
    "\n",
    "p300_rev_chr_resize <- resize(p300_rev_chr, width = 2000)\n",
    "p300_rev_final <- as.data.frame(p300_rev_chr_resize)\n",
    "p300_rev_final <- unique(p300_rev_final[,c(\"seqnames\",\"start\",\"end\")]) # removing redundant entries #\n",
    "export.bed(p300_rev_final, \"p300_rev_final.bed\")\n",
    "\n",
    "system(\"sortBed -i p300_rev_final.bed > p300_rev_final_sorted.bed\")\n",
    "system(\"awk '{print $1 \"\\t\" $2 \"\\t\" $3}' p300_rev_final_sorted.bed > p300_rev_finale.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the p300 bindings genomewide, we shall filter them for being distant to the promoter/TSS regions. Note that we are solely interested in the ones that are distal to the TSS; **distal as in non-proximal!**\n",
    "GRanges objects are workabkle for set operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p300_rev_finale <- import.bed(\"p300_rev_finale.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcription Start Sites  (TSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Wikipedia, an enhancer is a short (50-1500 bp) region of the DNA that can be bound by proteins. They can be located quite far from the promoter sequences of the genes that house the TSS. The transcription start sites' indices (start and end positions) are 'constant' throughout the genome. The gene positioning is the same across, rather the discrepenacy in distinct cell types is with the set of genes that get regulated. One source of downloading the TSS data is 'Ensembl Biomart'. <br>\n",
    "> Step 1: Choose 'Human genes' under 'Dataset' tab on the left pane. <br> <br>\n",
    "> Step 2: Under 'Attributes', select <br>\n",
    "    (i) Chromosome/ scaffold name <br>\n",
    "    (ii) Transcript start (bp) <br>\n",
    "    (iii) Transcript end (bp) <br> <br>\n",
    "> Step 3: Click on 'Results' button and download appropriately. <br>  \n",
    "The other sources are refTSS and DBTSS databases. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's pull the TSS sites\n",
    "\n",
    "tss_sites <- read.table(\"./data/H1_Cell_Line/TSS_Indices_Human_Genome.txt\", sep = \"\\t\", header = TRUE)\n",
    "tss_sites$Chromosome.scaffold.name <- paste0(\"chr\", tss_sites$Chromosome.scaffold.name)\n",
    "tss_sites <- as.data.frame(tss_sites[tss_sites$Chromosome.scaffold.name  %in% chromosomes, ])\n",
    "tss_sites <- tss_sites[order(tss_sites$Chromosome.scaffold.name),]\n",
    "colnames(tss_sites) <- c(\"chrom\", \"start\", \"end\")\n",
    "tss_rev <- GRanges(tss_sites)\n",
    "\n",
    "## We are going to shove off TSS sites that intersect with p300 binding sites. This will give us the distal p300 sites.\n",
    "\n",
    "p300_nonTSS <- setdiff(p300_rev_finale,tss_rev)\n",
    "export.bed(p300_nonTSS, \"p300_nonTSS.bed\")\n",
    "system(\"awk '{print $1 \"\\t\" $2 \"\\t\" $3}' p300_nonTSS.bed > p300_nonTSS_final.bed\")\n",
    "\n",
    "## Finally, saving as a intersection of distal p300 and DHS sites\n",
    "\n",
    "system(\"intersectBed -a dhs_finale_sorted.bed -b p300_nonTSS_final.bed > h1_distalp300_dhs_intersect.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated above, the DHS sites represent the open chromatin regions that are susceptible to protein bindings. Concurrently, p300 is a protein complex that is ranked high as a biomarker for enhancer regions. The probability that an intersection of p300 binding sites and open chromatin regions envisage enhancers is expounded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add class to the data: \"enhancer\"\n",
    "\n",
    "h1_distalp300_dhs_intersect <- read.table(\"h1_distalp300_dhs_intersect.bed\", sep = \"\\t\")\n",
    "h1_distalp300_dhs_intersect$V4 <- \"Enhancer\"\n",
    "write.table(h1_distalp300_dhs_intersect,\"h1_distalp300_dhs_intersect_class.bed\",sep=\"\\t\",row.names=FALSE, quote = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for the negative class labels, i.e. non-enhancers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Class Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For negative class, i.e. non-enhancers, we intend on a compendium of an intersection of transcription start sites and DHS sites, alongwith random tracks from the genome that are distal to p300 and TSS sites, serving as a background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we intend to find the intersection of TSS with DHS sites.\n",
    "dhs_min <- import.bed(\"dhs_finale_sorted.bed\")\n",
    "tss_dhs <- intersect(tss_rev, dhs_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Sites in the Human Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The other aspect for mapping negative class labels (non-enhancers) entails sourcing chromosomal lengths in the human genome for generating random tracks\n",
    "\n",
    "hg38_chrom_sizes <- read.table(url(\"https://genome.ucsc.edu/goldenPath/help/hg38.chrom.sizes\"), sep = \"\\t\", header = FALSE, col.names = c(\"chrom\", \"size\"))\n",
    "hg38_chrom_sizes <- as.data.frame(hg38_chrom_sizes[hg38_chrom_sizes$chrom %in% chromosomes, ])\n",
    "\n",
    "## Saving file for generating random tracks via 'bedtools random' function ##\n",
    "write.table(hg38_chrom_sizes,\"./data/H1_Cell_Line/hg38.genome\", sep=\"\\t\", row.names=FALSE, quote = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating random tracks\n",
    "\n",
    "system(\"bedtools random -l 2000 -g ./data/H1_Cell_Line/hg38.genome > ./data/H1_Cell_Line/hg38_random_tracks.bed\")\n",
    "\n",
    "## Recalling\n",
    "\n",
    "hg38_random_tracks <- read.table(\"./data/H1_Cell_Line/hg38_random_tracks.bed\", sep = \"\\t\", header = FALSE)\n",
    "hg38_random_tracks <- hg38_random_tracks[,c(1,2,3)]\n",
    "hg38_random_tracks_ordered <- hg38_random_tracks[order(hg38_random_tracks[,1],hg38_random_tracks[,2]),]\n",
    "\n",
    "write.table(hg38_random_tracks_ordered,\"./data/H1_Cell_Line/hg38_random_tracks_sorted_required.bed\", sep=\"\\t\", row.names=FALSE, quote = FALSE)\n",
    "colnames(hg38_random_tracks_ordered) <- c(\"chrom\", \"start\", \"end\")\n",
    "hg38_random <- GRanges(hg38_random_tracks_ordered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The option -l in *bedtools random* allows user to specifiy the interval size of the tracks that are to be randomly generated from the genome file. However this is optional, but in our case we have to stay in sync with the interval profiles tha twe selected for combining the score matrix for histone marks. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"mergeBed -i hg_random_tracks_sorted_required.bed > hg_random_tracks_sorted_required_merged.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"awk '{if (NR!=1) {print}}' hg_random_tracks_sorted_required_merged.bed > hg_random_tracks_sorted_required_merged_header_removed.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing random sites distal to TSS and p300 bindings\n",
    "\n",
    "## The strategy is to combine random tracks distal to the TSS or p300 binding sites. Now, let us create a \n",
    "## combination of TSS and p300 binding sites and then subtract the random sites from these, thus giving us\n",
    "## the residuals.\n",
    "\n",
    "\n",
    "## Combine the intervals and not 'merge' them\n",
    "p300_tss <- union(p300_rev_finale, tss_rev)\n",
    "\n",
    "\n",
    "## Inferring random tracks distal to p300 bindings and TSS sites.\n",
    "random_nonp300TSS <- setdiff(hg38_random,p300_tss)\n",
    "\n",
    "\n",
    "## Merging the aforementioned random tracks and the TSS, DHS intersection.\n",
    "random_tss_dhs <- union(random_nonp300TSS, tss_dhs)\n",
    "\n",
    "## Output file.\n",
    "write.table(random_tss_dhs,\"./data/H1_Cell_Line/random_tss_dhs.bed\", sep=\"\\t\", row.names=FALSE, quote = FALSE)\n",
    "system(\"awk '{if (NR!=1) {print}}' ./data/H1_Cell_Line/random_tss_dhs.bed > ./data/H1_Cell_Line/random_tss_dhs_header_removed.bed\")\n",
    "\n",
    "## Import resultant files from intersection.\n",
    "negative_class <- read.table(\"./data/H1_Cell_Line/random_tss_dhs_header_removed.bed\", sep = \"\\t\", header = FALSE)\n",
    "negative_class$V4 <- \"Non-Enhancer\"\n",
    "negative_class$V5 <- c() # removing strand information\n",
    "write.table(negative_class,\"./data/H1_Cell_Line/negative_class.bed\", sep=\"\\t\", row.names=FALSE, quote = FALSE)\n",
    "\n",
    "positive_class <- read.table(\"h1_distalp300_dhs_intersect_class.bed\", sep = \"\\t\", header = FALSE)\n",
    "\n",
    "## Saving auxilliary informaiton\n",
    "save(p300_rev, dhs_rev, file=\"aux.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again as before, we remove the header and and sort the file \"tss_and_p300.bed\". The resulting file is named \"tss_and_p300_header_removed_sorted.bed\". <br> Additionally, the resultant file after intersecting the TSS and DHS sites from H1 cell line is \"tss_h1_dhs_intersect_sorted_merged.bed\". <br>\n",
    "**The filenames are so chosen to reflect the order and type of manipulations that have been applied.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to consolidate the negative class data, we have to : <br>\n",
    "> 1. Find the random sites that are distal to known p300 and TSS regions. <br>\n",
    "> 2. Find the intersection of TSS and DHS sites. <br>\n",
    "> 3. Finally, club both of these together to represent a comprehensive non-enhancer region space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All the regions in the random sites of the human genome but not coinciding with the p300 and tss sites.\n",
    "system(\"intersectBed -v -a hg19_random_tracks_sorted_required_header_removed.bed -b tss_and_p300_header_removed_sorted.bed > true_random_to_p300_and_TSS.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"cat true_random_to_p300_and_TSS.bed tss_h1_dhs_intersect_sorted_merged.bed > negative_class.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import resultant files from intersection.\n",
    "negative_class <- read.table(\"./data/H1_Cell_Line/negative_class.bed\", sep = \"\\t\", header = FALSE)\n",
    "negative_class$V4 <- \"Non-Enhancer\"\n",
    "write.table(negative_class,\"./data/H1_Cell_Line/negative_class.bed\", sep=\"\\t\", row.names=FALSE, quote = FALSE)\n",
    "\n",
    "positive_class <- read.table(\"./data/H1_Cell_Line/h1_p300_dhs_intersect_class_header_removed.bed\", sep = \"\\t\", \n",
    "                             header = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>chr1</td><td>10101</td><td>10140</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>10148</td><td>10209</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>10235</td><td>10290</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>10444</td><td>10580</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>11362</td><td>11397</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>12302</td><td>12333</td><td>enhancer</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       " V1 & V2 & V3 & V4\\\\\n",
       " <fct> & <int> & <int> & <fct>\\\\\n",
       "\\hline\n",
       "\t chr1 & 10101 & 10140 & enhancer\\\\\n",
       "\t chr1 & 10148 & 10209 & enhancer\\\\\n",
       "\t chr1 & 10235 & 10290 & enhancer\\\\\n",
       "\t chr1 & 10444 & 10580 & enhancer\\\\\n",
       "\t chr1 & 11362 & 11397 & enhancer\\\\\n",
       "\t chr1 & 12302 & 12333 & enhancer\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| V1 &lt;fct&gt; | V2 &lt;int&gt; | V3 &lt;int&gt; | V4 &lt;fct&gt; |\n",
       "|---|---|---|---|\n",
       "| chr1 | 10101 | 10140 | enhancer |\n",
       "| chr1 | 10148 | 10209 | enhancer |\n",
       "| chr1 | 10235 | 10290 | enhancer |\n",
       "| chr1 | 10444 | 10580 | enhancer |\n",
       "| chr1 | 11362 | 11397 | enhancer |\n",
       "| chr1 | 12302 | 12333 | enhancer |\n",
       "\n"
      ],
      "text/plain": [
       "  V1   V2    V3    V4      \n",
       "1 chr1 10101 10140 enhancer\n",
       "2 chr1 10148 10209 enhancer\n",
       "3 chr1 10235 10290 enhancer\n",
       "4 chr1 10444 10580 enhancer\n",
       "5 chr1 11362 11397 enhancer\n",
       "6 chr1 12302 12333 enhancer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Merging Data on the basis of overlapping intervals\n",
    "\n",
    "## Positive class data (labels)\n",
    "head(positive_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>chr1</td><td>  847</td><td>  947</td><td>Non-Enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td> 8952</td><td> 9052</td><td>Non-Enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>39831</td><td>39931</td><td>Non-Enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>40608</td><td>40708</td><td>Non-Enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>43842</td><td>43942</td><td>Non-Enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>47908</td><td>48008</td><td>Non-Enhancer</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       " V1 & V2 & V3 & V4\\\\\n",
       " <fct> & <int> & <int> & <chr>\\\\\n",
       "\\hline\n",
       "\t chr1 &   847 &   947 & Non-Enhancer\\\\\n",
       "\t chr1 &  8952 &  9052 & Non-Enhancer\\\\\n",
       "\t chr1 & 39831 & 39931 & Non-Enhancer\\\\\n",
       "\t chr1 & 40608 & 40708 & Non-Enhancer\\\\\n",
       "\t chr1 & 43842 & 43942 & Non-Enhancer\\\\\n",
       "\t chr1 & 47908 & 48008 & Non-Enhancer\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| V1 &lt;fct&gt; | V2 &lt;int&gt; | V3 &lt;int&gt; | V4 &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| chr1 |   847 |   947 | Non-Enhancer |\n",
       "| chr1 |  8952 |  9052 | Non-Enhancer |\n",
       "| chr1 | 39831 | 39931 | Non-Enhancer |\n",
       "| chr1 | 40608 | 40708 | Non-Enhancer |\n",
       "| chr1 | 43842 | 43942 | Non-Enhancer |\n",
       "| chr1 | 47908 | 48008 | Non-Enhancer |\n",
       "\n"
      ],
      "text/plain": [
       "  V1   V2    V3    V4          \n",
       "1 chr1   847   947 Non-Enhancer\n",
       "2 chr1  8952  9052 Non-Enhancer\n",
       "3 chr1 39831 39931 Non-Enhancer\n",
       "4 chr1 40608 40708 Non-Enhancer\n",
       "5 chr1 43842 43942 Non-Enhancer\n",
       "6 chr1 47908 48008 Non-Enhancer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Negative class (Labels)\n",
    "head(negative_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: stats4\n",
      "Loading required package: BiocGenerics\n",
      "Loading required package: parallel\n",
      "\n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "The following objects are masked from ‘package:parallel’:\n",
      "\n",
      "    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,\n",
      "    clusterExport, clusterMap, parApply, parCapply, parLapply,\n",
      "    parLapplyLB, parRapply, parSapply, parSapplyLB\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    Filter, Find, Map, Position, Reduce, anyDuplicated, append,\n",
      "    as.data.frame, basename, cbind, colnames, dirname, do.call,\n",
      "    duplicated, eval, evalq, get, grep, grepl, intersect, is.unsorted,\n",
      "    lapply, mapply, match, mget, order, paste, pmax, pmax.int, pmin,\n",
      "    pmin.int, rank, rbind, rownames, sapply, setdiff, sort, table,\n",
      "    tapply, union, unique, unsplit, which, which.max, which.min\n",
      "\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    expand.grid\n",
      "\n",
      "Loading required package: IRanges\n",
      "Warning message:\n",
      "“package ‘IRanges’ was built under R version 3.6.1”Loading required package: GenomeInfoDb\n"
     ]
    }
   ],
   "source": [
    "## Score Matrix (Input data)\n",
    "input_score_data <- merged_bw\n",
    "input_score_data<- as.data.frame(input_score_data[input_score_data$chrom %in% chromosomes, ])\n",
    "\n",
    "\n",
    "## Replacing NAs with 0s(zeros) in the reads' columns. Since the score data is not available, imputing empty cells with\n",
    "## zero entries engenders mathematical convenience.\n",
    "\n",
    "input_score_data$H3K27ac[is.na(input_score_data$H3K27ac)] <- 0 \n",
    "input_score_data$H3K4me3[is.na(input_score_data$H3K4me3)] <- 0 \n",
    "input_score_data$H3K4me2[is.na(input_score_data$H3K4me2)] <- 0 \n",
    "input_score_data$H3K4me1[is.na(input_score_data$H3K4me1)] <- 0 \n",
    "\n",
    "## Converting data to GRanges objects\n",
    "positive_class <- positive_class[-1,]\n",
    "positive_class_labels <- GRanges(seqnames = positive_class$V1, ranges = IRanges(start = positive_class$V2, \n",
    "                                                                       end = positive_class$V3))\n",
    "mcols(positive_class_labels) <- DataFrame(class= \"enhancer\")\n",
    "\n",
    "\n",
    "negative_class_labels <- GRanges(seqnames = negative_class$V1, ranges = IRanges(start = negative_class$V2, \n",
    "                                                                       end = negative_class$V3))\n",
    "mcols(negative_class_labels) <- DataFrame(class= \"non-enhancer\")\n",
    "\n",
    "\n",
    "input_score <- GRanges(seqnames = input_score_data$chrom, ranges = IRanges(start = input_score_data$start,\n",
    "                                                                        end = input_score_data$end))\n",
    "mcols(input_score) <- DataFrame(reads_h3k27ac = input_score_data$H3K27ac, reads_h3k4me3 = input_score_data$H3K4me3,\n",
    "                                reads_h3k4me2 = input_score_data$H3K4me2, reads_h3k4me1 = input_score_data$H3K4me1)\n",
    "\n",
    "## Performing merge to figure out the score and class matrix.\n",
    "## Appending negative and positive class intervals together.\n",
    "\n",
    "positive_and_negative_class_intervals <- merge(as.data.frame(positive_class_labels), as.data.frame(negative_class_labels), all=TRUE) ## positive and negative classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting 'positive_and_negative_class_intervals' and 'input_score' as bed files to merge.**\n",
    "\n",
    "write.table(positive_and_negative_class_intervals, \"./data/class_labels.bed\", sep ='\\t', quote = FALSE, row.names = FALSE)\n",
    "write.table(input_score, \"./data/score.bed\", sep ='\\t', quote = FALSE, row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing for syntax and merging\n",
    "\n",
    "system(\"awk '{if (NR!=1) {print}}' ./data/class_labels.bed > ./data/class_labels_header_removed.bed\")\n",
    "system(\"awk '{if (NR!=1) {print}}' ./data/score.bed > ./data/score_header_removed.bed\")\n",
    "\n",
    "system(\"bedtools intersect -wa -wb -a ./data/score_header_removed.bed -b ./data/class_labels_header_removed.bed > ./data/score_labels.bed\")\n",
    "\n",
    "## While merging the intervals for class labels (positive and negative) and RPKM normalized scores, there are occassions where one interval of the latter may\n",
    "## encompass several intervals from the former. This is reflected in the 'bedtools intersect' operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we finally implement for the machine learning model is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the merged file\n",
    "score_labels <- read.table(\"./data/score_labels.bed\", sep = \"\\t\", header = FALSE, stringsAsFactors=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t19834154 obs. of  15 variables:\n",
      " $ V1 : chr  \"chr1\" \"chr1\" \"chr1\" \"chr1\" ...\n",
      " $ V2 : int  0 0 10100 10100 10100 10100 10100 10100 10100 10100 ...\n",
      " $ V3 : int  9900 9900 17400 17400 17400 17400 17400 17400 17400 17400 ...\n",
      " $ V4 : int  9901 9901 7301 7301 7301 7301 7301 7301 7301 7301 ...\n",
      " $ V5 : chr  \"*\" \"*\" \"*\" \"*\" ...\n",
      " $ V6 : chr  \"0\" \"0\" \"0\" \"0\" ...\n",
      " $ V7 : chr  \"0\" \"0\" \"0\" \"0\" ...\n",
      " $ V8 : chr  \"0\" \"0\" \"0\" \"0\" ...\n",
      " $ V9 : chr  \"0\" \"0\" \"0\" \"0\" ...\n",
      " $ V10: chr  \"chr1\" \"chr1\" \"chr1\" \"chr1\" ...\n",
      " $ V11: int  847 8952 10101 10148 10235 10444 11362 12302 12302 14931 ...\n",
      " $ V12: int  947 9052 10140 10209 10290 10580 11397 12333 12337 14956 ...\n",
      " $ V13: int  101 101 40 62 56 137 36 32 36 26 ...\n",
      " $ V14: chr  \"*\" \"*\" \"*\" \"*\" ...\n",
      " $ V15: chr  \"Non-Enhancer\" \"Non-Enhancer\" \"Enhancer\" \"Enhancer\" ...\n"
     ]
    }
   ],
   "source": [
    "str(score_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that our effective data is \"sparse\", i.e. there are less non-zero entries and a larger protion of the data is occupied by zeroes. A good strategy for optimization in terms of memory and also data processing is the usage of **sparse matrix** feature available from Matrix library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first isolate the actual input data from the entire dataframe and convert it into matrix format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in eval(expr, envir, enclos):\n",
      "“NAs introduced by coercion”Warning message in eval(expr, envir, enclos):\n",
      "“NAs introduced by coercion”Warning message in eval(expr, envir, enclos):\n",
      "“NAs introduced by coercion”Warning message in eval(expr, envir, enclos):\n",
      "“NAs introduced by coercion”"
     ]
    }
   ],
   "source": [
    "## Picking relevant columns\n",
    "final_data <- score_labels[,c(6:9,15)]\n",
    "colnames(final_data)=c(\"reads_h3k27ac\",\"reads_h3k4me3\",\"reads_h3k4me2\",\"reads_h3k4me1\",\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving this data\n",
    "saveRDS(final_data,\"./data/ep_data.rds\")\n",
    "\n",
    "## Sample data\n",
    "final_data_sample <- final_data[sample(nrow(final_data), 10000), ]\n",
    "saveRDS(final_data_sample,\"./data/ep_data_sample.rds\")\n",
    "\n",
    "## Saving relevant files\n",
    "save(positive_class_labels, tss_rev, p300_rev_finale, input_score, hg38_random, dhs_min, file = \"relevant_files.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kim, S. G., Harwani, M., Grama, A., & Chaterji, S. (2016). EP-DNN : A Deep Neural Network- Based Global Enhancer Prediction Algorithm. Nature Publishing Group, (November), 1–13. https://doi.org/10.1038/srep38433"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
