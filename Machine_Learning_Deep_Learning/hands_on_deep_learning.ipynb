{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning has conquered our digital space in a much conceivable way. Aritifical Intelligence is the umbrella discipline that describes the varied notions of the systemic behavior akin to humans. Unlike the common held adage, **Deep Learning** isn't a part of Machine Learning per se, rather it has evolved to be an exclusive stream altogether.  \n",
    "If we recall from the previous session, we discussed the relevance of decision trees and random forests and how crucial former is to the latter. The diversity and aggregation of results in the random forests engender them the alacrity to handle multidimensional data. Although, neural nets do not foster the *same* relationship with deep learning, it is of the utmost importance to fathom the concept prior to proceeding to the holistic theme of deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./props/AI_branches.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, deep learning is founded on **neural networks** that have, generally, outperformed other classification algorithms like Support Vector Machines (SVM), logistic regression, etc. *Neural Networks* are a specialized set of algorithms that work on assigning and moderating weights from the original data (input), across through the layers to the classification result (ouput).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./props/deep_learning_NN_better.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "> Loosely, Neural Networks is to Deep Learning as ________ is to Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be subjective instances of errors that a system would result, owing to some missing or conflicting dependencies. Few encountered are as under:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./props/install_keras_error.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow is the Google's offering for machine learning and deep learning related tasks; *Anaconda* and *Python* libraries are major requisites for *TensorFlow* deployment in R. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./props/install_keras_error1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often,\n",
    "- there is a missing declaration in the PATH variable, or \n",
    "- *Anaconda* and *Python* installations have suffered shadowing from the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./props/install_keras_error2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/hm/c3_fjypn62v5xh5b5ygv267m0000gn/T//Rtmp2lWxc5/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "## Install the package and load the library\n",
    "\n",
    "install.packages(\"neuralnet\", \n",
    "                 repos = \"https://mirrors.tuna.tsinghua.edu.cn/CRAN/\",\n",
    "                 dependencies = TRUE)\n",
    "library(neuralnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall selection of data and the analysis protocol has been loosely borrowed from Kim et al. (2016). Typically for a machine learning problem, we shall have a dataset (consolidated, with class and variable/ feature definitions) and that'll be bifurcated (typically in 3:7 or 2:8 proportions) to be used as testing and training sets respectively. Contrarily, in this study both the categories have been sourced differently as you'll see.\n",
    "In this exercise, we shall have positive and negative training examples for the training dataset but only positive examples for the test dataset. And that is perfectively fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing data, we consider data only for enhancers. Even with this data, we shall be able to evaluate the model's veracity of predicting positive examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted, the primary step is to source the BAM files, index them, and finally tranform into BEDGRAPH files. The column naming is done appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3k27ac <- read.csv(\"./data/H1_Cell_Line/H3K27ac/ENCFF663SAM.bw\", sep = '\\t', header = FALSE)\n",
    "colnames(h3k27ac) <- c(\"chrom\",\"start\",\"end\",\"peaks\")\n",
    "h3k4me3 <- read.csv(\"./data/H1_Cell_Line/H3K4me3/ENCFF340UJK.bw\", sep = '\\t', header = FALSE)\n",
    "colnames(h3k4me3) <- c(\"chrom\",\"start\",\"end\",\"peaks\")\n",
    "h3k4me2 <- read.csv(\"./data/H1_Cell_Line/H3K4me2/ENCFF799BDH.bw\", sep = '\\t', header = FALSE)\n",
    "colnames(h3k4me2) <- c(\"chrom\",\"start\",\"end\",\"peaks\")\n",
    "h3k4me1 <- read.csv(\"./data/H1_Cell_Line/H3K4me1/ENCFF441KOL.bw\", sep = '\\t', header = FALSE)\n",
    "colnames(h3k4me1) <- c(\"chrom\",\"start\",\"end\",\"peaks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files (with extension **.bw**) are eventually imported to the online Galaxy interface and executed for the *bedtools Merge* function. The four files showcasing various histone markers for enhancer data are merged together on the basis of overlapping intervals to get a matrix of peak counts that act as features to the 'enhancer' class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resultant file is eventually imported back to R for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>chrom</th><th scope=col>start</th><th scope=col>end</th><th scope=col>peaks_h3k27ac</th><th scope=col>peaks_h3k4me3</th><th scope=col>peaks_h3k4me2</th><th scope=col>peaks_h3k4me1</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>chr1</td><td>    0</td><td> 8000</td><td>0.0000000</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>chr1</td><td> 8000</td><td>12000</td><td>0.0567974</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>chr1</td><td>12000</td><td>16000</td><td>0.0000000</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>chr1</td><td>16000</td><td>18000</td><td>0.0567974</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>chr1</td><td>18000</td><td>40000</td><td>0.0000000</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>chr1</td><td>40000</td><td>42000</td><td>0.0567974</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       " chrom & start & end & peaks\\_h3k27ac & peaks\\_h3k4me3 & peaks\\_h3k4me2 & peaks\\_h3k4me1\\\\\n",
       " <fct> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t chr1 &     0 &  8000 & 0.0000000 & 0 & 0 & 0\\\\\n",
       "\t chr1 &  8000 & 12000 & 0.0567974 & 0 & 0 & 0\\\\\n",
       "\t chr1 & 12000 & 16000 & 0.0000000 & 0 & 0 & 0\\\\\n",
       "\t chr1 & 16000 & 18000 & 0.0567974 & 0 & 0 & 0\\\\\n",
       "\t chr1 & 18000 & 40000 & 0.0000000 & 0 & 0 & 0\\\\\n",
       "\t chr1 & 40000 & 42000 & 0.0567974 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| chrom &lt;fct&gt; | start &lt;int&gt; | end &lt;int&gt; | peaks_h3k27ac &lt;dbl&gt; | peaks_h3k4me3 &lt;dbl&gt; | peaks_h3k4me2 &lt;dbl&gt; | peaks_h3k4me1 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| chr1 |     0 |  8000 | 0.0000000 | 0 | 0 | 0 |\n",
       "| chr1 |  8000 | 12000 | 0.0567974 | 0 | 0 | 0 |\n",
       "| chr1 | 12000 | 16000 | 0.0000000 | 0 | 0 | 0 |\n",
       "| chr1 | 16000 | 18000 | 0.0567974 | 0 | 0 | 0 |\n",
       "| chr1 | 18000 | 40000 | 0.0000000 | 0 | 0 | 0 |\n",
       "| chr1 | 40000 | 42000 | 0.0567974 | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  chrom start end   peaks_h3k27ac peaks_h3k4me3 peaks_h3k4me2 peaks_h3k4me1\n",
       "1 chr1      0  8000 0.0000000     0             0             0            \n",
       "2 chr1   8000 12000 0.0567974     0             0             0            \n",
       "3 chr1  12000 16000 0.0000000     0             0             0            \n",
       "4 chr1  16000 18000 0.0567974     0             0             0            \n",
       "5 chr1  18000 40000 0.0000000     0             0             0            \n",
       "6 chr1  40000 42000 0.0567974     0             0             0            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>chrom</th><th scope=col>start</th><th scope=col>end</th><th scope=col>peaks_h3k27ac</th><th scope=col>peaks_h3k4me3</th><th scope=col>peaks_h3k4me2</th><th scope=col>peaks_h3k4me1</th><th scope=col>class</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>chr1</td><td>    0</td><td> 8000</td><td>0.0000000</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td> 8000</td><td>12000</td><td>0.0567974</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>12000</td><td>16000</td><td>0.0000000</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>16000</td><td>18000</td><td>0.0567974</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>18000</td><td>40000</td><td>0.0000000</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>chr1</td><td>40000</td><td>42000</td><td>0.0567974</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 8\n",
       "\\begin{tabular}{r|llllllll}\n",
       " chrom & start & end & peaks\\_h3k27ac & peaks\\_h3k4me3 & peaks\\_h3k4me2 & peaks\\_h3k4me1 & class\\\\\n",
       " <fct> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t chr1 &     0 &  8000 & 0.0000000 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t chr1 &  8000 & 12000 & 0.0567974 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t chr1 & 12000 & 16000 & 0.0000000 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t chr1 & 16000 & 18000 & 0.0567974 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t chr1 & 18000 & 40000 & 0.0000000 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t chr1 & 40000 & 42000 & 0.0567974 & 0 & 0 & 0 & enhancer\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 8\n",
       "\n",
       "| chrom &lt;fct&gt; | start &lt;int&gt; | end &lt;int&gt; | peaks_h3k27ac &lt;dbl&gt; | peaks_h3k4me3 &lt;dbl&gt; | peaks_h3k4me2 &lt;dbl&gt; | peaks_h3k4me1 &lt;dbl&gt; | class &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| chr1 |     0 |  8000 | 0.0000000 | 0 | 0 | 0 | enhancer |\n",
       "| chr1 |  8000 | 12000 | 0.0567974 | 0 | 0 | 0 | enhancer |\n",
       "| chr1 | 12000 | 16000 | 0.0000000 | 0 | 0 | 0 | enhancer |\n",
       "| chr1 | 16000 | 18000 | 0.0567974 | 0 | 0 | 0 | enhancer |\n",
       "| chr1 | 18000 | 40000 | 0.0000000 | 0 | 0 | 0 | enhancer |\n",
       "| chr1 | 40000 | 42000 | 0.0567974 | 0 | 0 | 0 | enhancer |\n",
       "\n"
      ],
      "text/plain": [
       "  chrom start end   peaks_h3k27ac peaks_h3k4me3 peaks_h3k4me2 peaks_h3k4me1\n",
       "1 chr1      0  8000 0.0000000     0             0             0            \n",
       "2 chr1   8000 12000 0.0567974     0             0             0            \n",
       "3 chr1  12000 16000 0.0000000     0             0             0            \n",
       "4 chr1  16000 18000 0.0567974     0             0             0            \n",
       "5 chr1  18000 40000 0.0000000     0             0             0            \n",
       "6 chr1  40000 42000 0.0567974     0             0             0            \n",
       "  class   \n",
       "1 enhancer\n",
       "2 enhancer\n",
       "3 enhancer\n",
       "4 enhancer\n",
       "5 enhancer\n",
       "6 enhancer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Importing the merged BEDGRAPH/BW file\n",
    "\n",
    "merged_bw <- read.csv(\"./data/H1_Cell_Line/bedtools_Merge_2000.bedgraph\", sep = '\\t', header = FALSE)\n",
    "#merged_bw <- merged_bw[-1,]\n",
    "colnames(merged_bw) <- c(\"chrom\", \"start\", \"end\", \"peaks_h3k27ac\", \"peaks_h3k4me3\", \"peaks_h3k4me2\", \"peaks_h3k4me1\")\n",
    "head(merged_bw)\n",
    "merged_bw$class <- \"enhancer\"\n",
    "head(merged_bw)\n",
    "\n",
    "\n",
    "## Identifying examples of standard chromosomes only and filtering the residuals.\n",
    "\n",
    "chromosomes <- c(\"chr1\",\"chr2\",\"chr3\",\"chr4\",\"chr5\",\"chr6\",\"chr7\",\"chr8\",\"chr9\",\"chr10\",\"chr11\",\"chr12\",\"chr13\",\"chr14\",\n",
    "                 \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\",\"chr21\", \"chr22\", \"chrX\", \"chrY\")\n",
    "merged_bw<- as.data.frame(merged_bw[merged_bw$chrom %in% chromosomes, ])\n",
    "\n",
    "\n",
    "## Deriving test data as input to the deep learning model.\n",
    "\n",
    "test <- merged_bw[,c(4:8)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>peaks_h3k27ac</th><th scope=col>peaks_h3k4me3</th><th scope=col>peaks_h3k4me2</th><th scope=col>peaks_h3k4me1</th><th scope=col>class</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.0000000</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0</td><td>0</td><td>0</td><td>enhancer</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " peaks\\_h3k27ac & peaks\\_h3k4me3 & peaks\\_h3k4me2 & peaks\\_h3k4me1 & class\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0.0000000 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t 0.0567974 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t 0.0000000 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t 0.0567974 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t 0.0000000 & 0 & 0 & 0 & enhancer\\\\\n",
       "\t 0.0567974 & 0 & 0 & 0 & enhancer\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| peaks_h3k27ac &lt;dbl&gt; | peaks_h3k4me3 &lt;dbl&gt; | peaks_h3k4me2 &lt;dbl&gt; | peaks_h3k4me1 &lt;dbl&gt; | class &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 0.0000000 | 0 | 0 | 0 | enhancer |\n",
       "| 0.0567974 | 0 | 0 | 0 | enhancer |\n",
       "| 0.0000000 | 0 | 0 | 0 | enhancer |\n",
       "| 0.0567974 | 0 | 0 | 0 | enhancer |\n",
       "| 0.0000000 | 0 | 0 | 0 | enhancer |\n",
       "| 0.0567974 | 0 | 0 | 0 | enhancer |\n",
       "\n"
      ],
      "text/plain": [
       "  peaks_h3k27ac peaks_h3k4me3 peaks_h3k4me2 peaks_h3k4me1 class   \n",
       "1 0.0000000     0             0             0             enhancer\n",
       "2 0.0567974     0             0             0             enhancer\n",
       "3 0.0000000     0             0             0             enhancer\n",
       "4 0.0567974     0             0             0             enhancer\n",
       "5 0.0000000     0             0             0             enhancer\n",
       "6 0.0567974     0             0             0             enhancer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep learning model has two basic requisites with the input data.\n",
    "1. The data has to be *numeric* in type.\n",
    "2. It has to range from 0 to 1. So if it isn't already, some sort of normalization procedure can help do that. The preferred one is the min-max normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming to numeric(double).\n",
    "\n",
    "test$peaks_h3k27ac <- as.double(as.character(test$peaks_h3k27ac))\n",
    "test$peaks_h3k4me3 <- as.double(as.character(test$peaks_h3k4me3))\n",
    "test$peaks_h3k4me2 <- as.double(as.character(test$peaks_h3k4me2))\n",
    "test$peaks_h3k4me1 <- as.double(as.character(test$peaks_h3k4me1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1400659 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>peaks_h3k27ac</th><th scope=col>peaks_h3k4me3</th><th scope=col>peaks_h3k4me2</th><th scope=col>peaks_h3k4me1</th><th scope=col>class</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0432946</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0404528</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0865892</td><td>0.0404528</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0367072</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0404528</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0404528</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0432946</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.1135950</td><td>0.3463570</td><td>0.2022640</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.1135950</td><td>1.0390700</td><td>5.0161500</td><td>0.6974370</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.2271900</td><td>0.3030620</td><td>0.1213590</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>0.1703920</td><td>0.2164730</td><td>0.2427170</td><td>0.2936580</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.6061240</td><td>0.3640760</td><td>0.4404860</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.1703920</td><td>0.5628300</td><td>0.5663400</td><td>0.1835360</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.1135950</td><td>0.8225970</td><td>0.4045280</td><td>0.5873150</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.1135950</td><td>0.4762410</td><td>0.2427170</td><td>0.6240220</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.1731780</td><td>0.1213590</td><td>0.2936580</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.2597680</td><td>0.1213590</td><td>0.2936580</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0432946</td><td>0.2022640</td><td>0.2202430</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0432946</td><td>0.1213590</td><td>0.1468290</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0865892</td><td>0.0000000</td><td>0.2202430</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0865892</td><td>0.0404528</td><td>0.4404860</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.1298840</td><td>0.1618110</td><td>0.2569500</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0865892</td><td>0.0809057</td><td>0.0734144</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.1135950</td><td>0.0865892</td><td>0.0809057</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0432946</td><td>0.0000000</td><td>0.0734144</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.1298840</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0404528</td><td>0.0734144</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0432946</td><td>0.0404528</td><td>0.1468290</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0432946</td><td>0.1213590</td><td>0.2202430</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0865892</td><td>0.0000000</td><td>0.0734144</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0367072</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0432946</td><td>0.0404528</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0000000</td><td>0.0367072</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0567974</td><td>0.0000000</td><td>0.0404528</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0404528</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "\t<tr><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>0.0000000</td><td>enhancer</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1400659 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " peaks\\_h3k27ac & peaks\\_h3k4me3 & peaks\\_h3k4me2 & peaks\\_h3k4me1 & class\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0432946 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0404528 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0865892 & 0.0404528 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0367072 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0404528 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0404528 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0432946 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.1135950 & 0.3463570 & 0.2022640 & 0.0000000 & enhancer\\\\\n",
       "\t 0.1135950 & 1.0390700 & 5.0161500 & 0.6974370 & enhancer\\\\\n",
       "\t 0.2271900 & 0.3030620 & 0.1213590 & 0.0000000 & enhancer\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 0.1703920 & 0.2164730 & 0.2427170 & 0.2936580 & enhancer\\\\\n",
       "\t 0.0567974 & 0.6061240 & 0.3640760 & 0.4404860 & enhancer\\\\\n",
       "\t 0.1703920 & 0.5628300 & 0.5663400 & 0.1835360 & enhancer\\\\\n",
       "\t 0.1135950 & 0.8225970 & 0.4045280 & 0.5873150 & enhancer\\\\\n",
       "\t 0.1135950 & 0.4762410 & 0.2427170 & 0.6240220 & enhancer\\\\\n",
       "\t 0.0567974 & 0.1731780 & 0.1213590 & 0.2936580 & enhancer\\\\\n",
       "\t 0.0000000 & 0.2597680 & 0.1213590 & 0.2936580 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0432946 & 0.2022640 & 0.2202430 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0432946 & 0.1213590 & 0.1468290 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0865892 & 0.0000000 & 0.2202430 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0865892 & 0.0404528 & 0.4404860 & enhancer\\\\\n",
       "\t 0.0567974 & 0.1298840 & 0.1618110 & 0.2569500 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0865892 & 0.0809057 & 0.0734144 & enhancer\\\\\n",
       "\t 0.1135950 & 0.0865892 & 0.0809057 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0432946 & 0.0000000 & 0.0734144 & enhancer\\\\\n",
       "\t 0.0567974 & 0.1298840 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0404528 & 0.0734144 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0432946 & 0.0404528 & 0.1468290 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0432946 & 0.1213590 & 0.2202430 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0865892 & 0.0000000 & 0.0734144 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0367072 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0432946 & 0.0404528 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0000000 & 0.0367072 & enhancer\\\\\n",
       "\t 0.0567974 & 0.0000000 & 0.0404528 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0404528 & 0.0000000 & enhancer\\\\\n",
       "\t 0.0000000 & 0.0000000 & 0.0000000 & 0.0000000 & enhancer\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1400659 × 5\n",
       "\n",
       "| peaks_h3k27ac &lt;dbl&gt; | peaks_h3k4me3 &lt;dbl&gt; | peaks_h3k4me2 &lt;dbl&gt; | peaks_h3k4me1 &lt;dbl&gt; | class &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0432946 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0404528 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0865892 | 0.0404528 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0367072 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0404528 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0404528 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0432946 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.1135950 | 0.3463570 | 0.2022640 | 0.0000000 | enhancer |\n",
       "| 0.1135950 | 1.0390700 | 5.0161500 | 0.6974370 | enhancer |\n",
       "| 0.2271900 | 0.3030620 | 0.1213590 | 0.0000000 | enhancer |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 0.1703920 | 0.2164730 | 0.2427170 | 0.2936580 | enhancer |\n",
       "| 0.0567974 | 0.6061240 | 0.3640760 | 0.4404860 | enhancer |\n",
       "| 0.1703920 | 0.5628300 | 0.5663400 | 0.1835360 | enhancer |\n",
       "| 0.1135950 | 0.8225970 | 0.4045280 | 0.5873150 | enhancer |\n",
       "| 0.1135950 | 0.4762410 | 0.2427170 | 0.6240220 | enhancer |\n",
       "| 0.0567974 | 0.1731780 | 0.1213590 | 0.2936580 | enhancer |\n",
       "| 0.0000000 | 0.2597680 | 0.1213590 | 0.2936580 | enhancer |\n",
       "| 0.0000000 | 0.0432946 | 0.2022640 | 0.2202430 | enhancer |\n",
       "| 0.0000000 | 0.0432946 | 0.1213590 | 0.1468290 | enhancer |\n",
       "| 0.0000000 | 0.0865892 | 0.0000000 | 0.2202430 | enhancer |\n",
       "| 0.0000000 | 0.0865892 | 0.0404528 | 0.4404860 | enhancer |\n",
       "| 0.0567974 | 0.1298840 | 0.1618110 | 0.2569500 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0865892 | 0.0809057 | 0.0734144 | enhancer |\n",
       "| 0.1135950 | 0.0865892 | 0.0809057 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0432946 | 0.0000000 | 0.0734144 | enhancer |\n",
       "| 0.0567974 | 0.1298840 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0404528 | 0.0734144 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0432946 | 0.0404528 | 0.1468290 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0432946 | 0.1213590 | 0.2202430 | enhancer |\n",
       "| 0.0000000 | 0.0865892 | 0.0000000 | 0.0734144 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0367072 | enhancer |\n",
       "| 0.0000000 | 0.0432946 | 0.0404528 | 0.0000000 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0000000 | 0.0367072 | enhancer |\n",
       "| 0.0567974 | 0.0000000 | 0.0404528 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0404528 | 0.0000000 | enhancer |\n",
       "| 0.0000000 | 0.0000000 | 0.0000000 | 0.0000000 | enhancer |\n",
       "\n"
      ],
      "text/plain": [
       "        peaks_h3k27ac peaks_h3k4me3 peaks_h3k4me2 peaks_h3k4me1 class   \n",
       "1       0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "2       0.0567974     0.0000000     0.0000000     0.0000000     enhancer\n",
       "3       0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "4       0.0567974     0.0000000     0.0000000     0.0000000     enhancer\n",
       "5       0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "6       0.0567974     0.0000000     0.0000000     0.0000000     enhancer\n",
       "7       0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "8       0.0567974     0.0000000     0.0000000     0.0000000     enhancer\n",
       "9       0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "10      0.0567974     0.0432946     0.0000000     0.0000000     enhancer\n",
       "11      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "12      0.0000000     0.0000000     0.0404528     0.0000000     enhancer\n",
       "13      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "14      0.0567974     0.0865892     0.0404528     0.0000000     enhancer\n",
       "15      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "16      0.0567974     0.0000000     0.0000000     0.0000000     enhancer\n",
       "17      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "18      0.0567974     0.0000000     0.0000000     0.0367072     enhancer\n",
       "19      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "20      0.0000000     0.0000000     0.0404528     0.0000000     enhancer\n",
       "21      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "22      0.0567974     0.0000000     0.0000000     0.0000000     enhancer\n",
       "23      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "24      0.0000000     0.0000000     0.0404528     0.0000000     enhancer\n",
       "25      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "26      0.0000000     0.0432946     0.0000000     0.0000000     enhancer\n",
       "27      0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "28      0.1135950     0.3463570     0.2022640     0.0000000     enhancer\n",
       "29      0.1135950     1.0390700     5.0161500     0.6974370     enhancer\n",
       "30      0.2271900     0.3030620     0.1213590     0.0000000     enhancer\n",
       "⋮       ⋮             ⋮             ⋮             ⋮             ⋮       \n",
       "1400630 0.1703920     0.2164730     0.2427170     0.2936580     enhancer\n",
       "1400631 0.0567974     0.6061240     0.3640760     0.4404860     enhancer\n",
       "1400632 0.1703920     0.5628300     0.5663400     0.1835360     enhancer\n",
       "1400633 0.1135950     0.8225970     0.4045280     0.5873150     enhancer\n",
       "1400634 0.1135950     0.4762410     0.2427170     0.6240220     enhancer\n",
       "1400635 0.0567974     0.1731780     0.1213590     0.2936580     enhancer\n",
       "1400636 0.0000000     0.2597680     0.1213590     0.2936580     enhancer\n",
       "1400637 0.0000000     0.0432946     0.2022640     0.2202430     enhancer\n",
       "1400638 0.0000000     0.0432946     0.1213590     0.1468290     enhancer\n",
       "1400639 0.0000000     0.0865892     0.0000000     0.2202430     enhancer\n",
       "1400640 0.0000000     0.0865892     0.0404528     0.4404860     enhancer\n",
       "1400641 0.0567974     0.1298840     0.1618110     0.2569500     enhancer\n",
       "1400642 0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "1400643 0.0567974     0.0865892     0.0809057     0.0734144     enhancer\n",
       "1400644 0.1135950     0.0865892     0.0809057     0.0000000     enhancer\n",
       "1400645 0.0567974     0.0432946     0.0000000     0.0734144     enhancer\n",
       "1400646 0.0567974     0.1298840     0.0000000     0.0000000     enhancer\n",
       "1400647 0.0000000     0.0000000     0.0404528     0.0734144     enhancer\n",
       "1400648 0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "1400649 0.0000000     0.0432946     0.0404528     0.1468290     enhancer\n",
       "1400650 0.0567974     0.0000000     0.0000000     0.0000000     enhancer\n",
       "1400651 0.0000000     0.0432946     0.1213590     0.2202430     enhancer\n",
       "1400652 0.0000000     0.0865892     0.0000000     0.0734144     enhancer\n",
       "1400653 0.0000000     0.0000000     0.0000000     0.0367072     enhancer\n",
       "1400654 0.0000000     0.0432946     0.0404528     0.0000000     enhancer\n",
       "1400655 0.0567974     0.0000000     0.0000000     0.0367072     enhancer\n",
       "1400656 0.0567974     0.0000000     0.0404528     0.0000000     enhancer\n",
       "1400657 0.0000000     0.0000000     0.0000000     0.0000000     enhancer\n",
       "1400658 0.0000000     0.0000000     0.0404528     0.0000000     enhancer\n",
       "1400659 0.0000000     0.0000000     0.0000000     0.0000000     enhancer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## For fair results, let's make sure that no \"NA\" values exist.\n",
    "na.omit(test)\n",
    "\n",
    "## Min-Max normalization\n",
    "test$peaks_h3k27ac <- (test$peaks_h3k27ac-min(test$peaks_h3k27ac, na.rm = T))/(max(test$peaks_h3k27ac, na.rm = T)-min(test$peaks_h3k27ac, na.rm = T))\n",
    "test$peaks_h3k4me3 <- (test$peaks_h3k4me3-min(test$peaks_h3k4me3, na.rm = T))/(max(test$peaks_h3k4me3, na.rm = T)-min(test$peaks_h3k4me3, na.rm = T))\n",
    "test$peaks_h3k4me2 <- (test$peaks_h3k4me2-min(test$peaks_h3k4me2, na.rm = T))/(max(test$peaks_h3k4me2, na.rm = T)-min(test$peaks_h3k4me2, na.rm = T))\n",
    "test$peaks_h3k4me1 <- (test$peaks_h3k4me1-min(test$peaks_h3k4me1, na.rm = T))/(max(test$peaks_h3k4me1, na.rm = T)-min(test$peaks_h3k4me1, na.rm = T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcription Start Sites  (TSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Wikipedia, an enhancer is a short (50-1500 bp) region of the DNA that can be bound by proteins. They can be located quite far from the promoter sequences of the genes that house the TSS. The transcription start sites' indices (start and end positions) are 'constant' throughout the genome. The gene positioning is the same across, rather the discrepenacy in distinct cell types is with the set of genes that get regulated. One source of downloading the TSS data is 'Ensembl Biomart'.\n",
    "> Step 1: Choose 'Human genes' under 'Dataset' tab on the left pane.\n",
    "> Step 2: Under 'Attributes', select\n",
    "    (i) Chromosome/ scaffold name\n",
    "    (ii) Transcript start (bp)\n",
    "    (iii) Transcript end (bp)\n",
    "> Step 3: Click on 'Results' button and download appropriately.  \n",
    "The other sources are refTSS and DBTSS databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in neuralnet(class ~ peaks_h3k4me3 + peaks_h3k4me2 + peaks_h3k4me1 + : could not find function \"neuralnet\"\n",
     "output_type": "error",
     "traceback": [
      "Error in neuralnet(class ~ peaks_h3k4me3 + peaks_h3k4me2 + peaks_h3k4me1 + : could not find function \"neuralnet\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Data Partition\n",
    "set.seed(108)\n",
    "ind <- sample(2, nrow(test), replace = TRUE, prob = c(0.7, 0.3))\n",
    "training <- test[ind==1,]\n",
    "testing <- test[ind==2,]\n",
    "\n",
    "# Neural Networks\n",
    "set.seed(007)\n",
    "nn <- neuralnet(class~peaks_h3k4me3+peaks_h3k4me2+peaks_h3k4me1+peaks_h3k27ac,\n",
    "               data = training,\n",
    "               hidden = 5,\n",
    "               err.fct = \"sse\",\n",
    "               act.fct = \"logistic\",\n",
    "               linear.output = FALSE)\n",
    "plot(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kim, S. G., Harwani, M., Grama, A., & Chaterji, S. (2016). EP-DNN : A Deep Neural Network- Based Global Enhancer Prediction Algorithm. Nature Publishing Group, (November), 1–13. https://doi.org/10.1038/srep38433"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
